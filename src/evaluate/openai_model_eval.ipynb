{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate fintuend model on customized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0,'../libs')\n",
    "import pandas as pd\n",
    "import openai,json\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from oai_fintune_utils import load_jsonl\n",
    "from pydantic import BaseModel\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "env_path = '../../.env'\n",
    "load_dotenv(dotenv_path=env_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='/root/data/home/xiong/data/Fund/CSR'\n",
    "fintune_data_folder=os.path.join(data_folder,'Fintuning_data','Monetary')\n",
    "train_data_path = os.path.join(fintune_data_folder,'train_mon_stance.jsonl')\n",
    "eval_data_path = os.path.join(fintune_data_folder,'test_mon_stance.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= load_jsonl(train_data_path)\n",
    "eval_data= load_jsonl(eval_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'You are an experience macroeconomist from IMF. \\nGiven a piece of text concerning a particular country in a given year expressing the views of IMF staff, complete the following two tasks. \\n\\nFirst, classify the country\\'s recent or current monetary policy stance as described in the text into \\n**restrictive/neutral/accommodative/unclear/irrelevant**; \\nif it discusses monetary policy but the specific stance is not clear, assign unclear; \\nif it does not discuss monetary policy, assign irrelevant. \\n\\nSecond, classify the IMF staff\\'s recommended or planned near-future (next year) direction of change in monetary policy stance \\nas described in the text into **tightening/tightening bias/no change/loosening bias/loosening/unclear/irrelevant**; \\nif it discusses monetary policy stance but the direction of change is not clear, assign no change; \\nif it does not discuss monetary policy stance, assign unclear (if it discusses monetary policy) \\nor irrelevant (if it does not discuss monetary policy). \\n\\nReturn a JSON dict without additional texts as follows: \\n```json\\n{\"stance_current\": \"<stance_current>\", \\n\"stance_future\": \"<stance_future>\"}\\n```\\n'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Country: Tunisia; Year: 2015\\nText:\\n60. Monetary policy should remain prudent. Staff welcomes the recent move toward positive real interest rates and the authorities’ readiness to raise interest rates should inflationary pressures increase. The monetary policy transmission mechanism would be greatly enhanced by removing the cap on lending rates and establishing a lender of last resort mechanism.'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '{\"stance_current\": \"restrictive\", \"stance_future\": \"tightening bias\"}'}]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'system',\n",
       " 'content': 'You are an experience macroeconomist from IMF. \\nGiven a piece of text concerning a particular country in a given year expressing the views of IMF staff, complete the following two tasks. \\n\\nFirst, classify the country\\'s recent or current monetary policy stance as described in the text into \\n**restrictive/neutral/accommodative/unclear/irrelevant**; \\nif it discusses monetary policy but the specific stance is not clear, assign unclear; \\nif it does not discuss monetary policy, assign irrelevant. \\n\\nSecond, classify the IMF staff\\'s recommended or planned near-future (next year) direction of change in monetary policy stance \\nas described in the text into **tightening/tightening bias/no change/loosening bias/loosening/unclear/irrelevant**; \\nif it discusses monetary policy stance but the direction of change is not clear, assign no change; \\nif it does not discuss monetary policy stance, assign unclear (if it discusses monetary policy) \\nor irrelevant (if it does not discuss monetary policy). \\n\\nReturn a JSON dict without additional texts as follows: \\n```json\\n{\"stance_current\": \"<stance_current>\", \\n\"stance_future\": \"<stance_future>\"}\\n```\\n'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['messages'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Fintuned Model Id from OAI website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class output(BaseModel):\n",
    "    stance_current: str\n",
    "    stance_future: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try one instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stance_current='restrictive' stance_future='tightening bias'\n"
     ]
    }
   ],
   "source": [
    "model_id = \"ft:gpt-4o-mini-2024-07-18:personal::AKfGCd2g\"\n",
    "\n",
    "## create clinet and test api key\n",
    "client = openai.OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "## run one test \n",
    "messages=[\n",
    "    train_data[0]['messages'][0],\n",
    "    train_data[0]['messages'][1],\n",
    "]\n",
    "## just run one test, make sure the api works \n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=model_id, \n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    response_format=output\n",
    ")\n",
    "print(response.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run through all training datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oai_outputs(data):\n",
    "    oai_outputs = []\n",
    "    for td in tqdm(data):\n",
    "        messages = td['messages'][:2]\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=model_id, \n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            response_format=output\n",
    "        )\n",
    "        oai_outputs.append(response.choices[0].message.parsed)\n",
    "    return oai_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [06:24<00:00,  1.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8311688311688312"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_oai_outputs = get_oai_outputs(train_data)\n",
    "train_ground_truth = [eval(td['messages'][-1]['content'])['stance_current'] for td in train_data]\n",
    "model_outputs = [td.stance_current for td in train_oai_outputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data accuracy: 0.8311688311688312\n"
     ]
    }
   ],
   "source": [
    "print('training data accuracy: {}'.format(accuracy_score(train_ground_truth,model_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 116/116 [01:25<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_oai_outputs = get_oai_outputs(eval_data)\n",
    "train_ground_truth = [eval(td['messages'][-1]['content'])['stance_current'] for td in eval_data]\n",
    "eval_model_outputs = [td.stance_current for td in eval_oai_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155172413793104"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_ground_truth,eval_model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
